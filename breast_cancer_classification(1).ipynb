{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "c6501100",
      "cell_type": "markdown",
      "source": "# Supervised Mini Project â€“ Breast Cancer Classification",
      "metadata": {}
    },
    {
      "id": "4423957a",
      "cell_type": "markdown",
      "source": "## 1. Import Required Libraries",
      "metadata": {}
    },
    {
      "id": "ccc41f3d",
      "cell_type": "code",
      "source": "\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0de90c9b",
      "cell_type": "markdown",
      "source": "## 2. Load Dataset (Local CSV)",
      "metadata": {}
    },
    {
      "id": "b8c60720",
      "cell_type": "code",
      "source": "\ndf = pd.read_csv(\"notebooks/breast cancer wisconsin diagnostic.csv\")\ndf.head()\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "89ec80a2",
      "cell_type": "markdown",
      "source": "## 3. Data Preprocessing",
      "metadata": {}
    },
    {
      "id": "8befff46",
      "cell_type": "code",
      "source": "\nX = df.drop('target', axis=1)\ny = df['target']\n\n# Handle missing values\nX = X.fillna(X.mean())\n\n# Feature scaling\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42\n)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c5e8a865",
      "cell_type": "markdown",
      "source": "## 4. Classification Models",
      "metadata": {}
    },
    {
      "id": "5952cbb7",
      "cell_type": "code",
      "source": "\n# Logistic Regression\nlr = LogisticRegression(max_iter=5000)\nlr.fit(X_train, y_train)\ny_pred_lr = lr.predict(X_test)\n\n# Decision Tree\ndt = DecisionTreeClassifier(random_state=42)\ndt.fit(X_train, y_train)\ny_pred_dt = dt.predict(X_test)\n\n# Random Forest\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\n\n# SVM\nsvm = SVC(kernel='rbf')\nsvm.fit(X_train, y_train)\ny_pred_svm = svm.predict(X_test)\n\n# k-NN\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred_knn = knn.predict(X_test)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e08d15df",
      "cell_type": "markdown",
      "source": "## 5. Model Evaluation",
      "metadata": {}
    },
    {
      "id": "e1092aa6",
      "cell_type": "code",
      "source": "\nmodels = {\n    'Logistic Regression': y_pred_lr,\n    'Decision Tree': y_pred_dt,\n    'Random Forest': y_pred_rf,\n    'SVM': y_pred_svm,\n    'k-NN': y_pred_knn\n}\n\nfor name, y_pred in models.items():\n    print(name)\n    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n    print(classification_report(y_test, y_pred))\n    print(\"-\" * 50)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c592e4bf",
      "cell_type": "markdown",
      "source": "## Conclusion\nSVM and Random Forest generally perform best, while Decision Trees may overfit.",
      "metadata": {}
    }
  ]
}